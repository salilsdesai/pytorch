{
  "torch.amp.autocast_mode": [
    "Any",
    "Optional"
  ],
  "torch.ao.nn.sparse.quantized.dynamic.linear": [
    "LinearBlockSparsePattern",
    "Optional",
    "hide_packed_params_repr"
  ],
  "torch.ao.nn.sparse.quantized.linear": [
    "Optional",
    "hide_packed_params_repr"
  ],
  "torch.ao.quantization": [
    "ABC",
    "ABCMeta",
    "Any",
    "Callable",
    "Dict",
    "List",
    "Module",
    "Optional",
    "OrderedDict",
    "Pattern",
    "QConfigAny",
    "Set",
    "Tuple",
    "Type",
    "Union",
    "abstractmethod",
    "namedtuple",
    "partial",
    "type_before_parametrizations",
    "wrap_cpp_module"
  ],
  "torch.ao.quantization.fake_quantize": [
    "ABC",
    "Any",
    "FixedQParamsObserver",
    "HistogramObserver",
    "Module",
    "MovingAverageMinMaxObserver",
    "MovingAveragePerChannelMinMaxObserver",
    "Tuple",
    "abstractmethod",
    "default_affine_fixed_qparams_fake_quant",
    "default_affine_fixed_qparams_observer",
    "default_dynamic_fake_quant",
    "default_embedding_fake_quant",
    "default_embedding_fake_quant_4bit",
    "default_fake_quant",
    "default_fused_act_fake_quant",
    "default_fused_per_channel_wt_fake_quant",
    "default_fused_wt_fake_quant",
    "default_histogram_fake_quant",
    "default_per_channel_weight_fake_quant",
    "default_symmetric_fixed_qparams_fake_quant",
    "default_symmetric_fixed_qparams_observer",
    "default_weight_fake_quant",
    "fused_per_channel_wt_fake_quant_range_neg_127_to_127",
    "fused_wt_fake_quant_range_neg_127_to_127"
  ],
  "torch.ao.quantization.fuse_modules": [
    "List",
    "Optional",
    "fuse_conv_bn",
    "fuse_conv_bn_relu",
    "get_fuser_method",
    "type_before_parametrizations"
  ],
  "torch.ao.quantization.fuser_method_mappings": [
    "Callable",
    "Dict",
    "MatchAllNode",
    "Optional",
    "Pattern",
    "Tuple",
    "Type",
    "Union",
    "get_combined_dict"
  ],
  "torch.ao.quantization.fx.backend_config.fuse_handler": [
    "DefaultFuseHandler"
  ],
  "torch.ao.quantization.fx.backend_config.native": [
    "Any",
    "Dict",
    "FixedQParamsFakeQuantize",
    "List",
    "ObservationType",
    "default_affine_fixed_qparams_observer",
    "default_symmetric_fixed_qparams_observer",
    "fuse_conv_bn",
    "fuse_conv_bn_relu",
    "fuse_convtranspose_bn",
    "fuse_linear_bn",
    "namedtuple",
    "reverse2",
    "reverse3",
    "reverse_sequential_wrapper2"
  ],
  "torch.ao.quantization.fx.backend_config.observation_type": [
    "Enum"
  ],
  "torch.ao.quantization.fx.backend_config.quantize_handler": [
    "Any",
    "Callable",
    "Dict",
    "NodePattern",
    "ObservationType",
    "Optional",
    "Pattern",
    "QuantizeHandler",
    "activation_dtype"
  ],
  "torch.ao.quantization.fx.backend_config.tensorrt": [
    "ObservationType",
    "reverse_sequential_wrapper2"
  ],
  "torch.ao.quantization.fx.backend_config.utils": [
    "Any",
    "Callable",
    "Dict",
    "List",
    "Pattern",
    "QuantizerCls",
    "Tuple",
    "Union",
    "get_combined_dict",
    "get_default_quant_patterns",
    "get_fuse_handler_cls",
    "get_native_backend_config_dict",
    "get_quantize_handler_cls",
    "sorted_patterns_dict"
  ],
  "torch.ao.quantization.fx.convert": [
    "Any",
    "Argument",
    "Callable",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "Node",
    "Optional",
    "Pattern",
    "QConfigAny",
    "QuantizeHandler",
    "QuantizedGraphModule",
    "Set",
    "Tuple",
    "activation_is_statically_quantized",
    "collect_producer_nodes",
    "compare_prepare_convert_qconfig_dict",
    "convert_dict_to_ordered_dict",
    "convert_eq_obs",
    "create_getattr_from_value",
    "generate_qconfig_map",
    "get_custom_module_class_keys",
    "get_fused_module_classes",
    "get_native_backend_config_dict",
    "get_pattern_to_dtype_configs",
    "get_qat_module_classes",
    "get_qparam_dict",
    "get_quantize_node_info",
    "get_root_module_to_quantized_reference_module",
    "get_swapped_custom_module_class",
    "graph_module_from_producer_nodes",
    "is_activation_post_process",
    "is_observed_module",
    "is_observed_standalone_module",
    "is_qconfig_supported_by_dtype_configs",
    "lower_to_fbgemm",
    "qconfig_equals",
    "update_obs_for_equalization",
    "update_qconfig_for_fusion",
    "update_qconfig_for_qat",
    "weight_is_quantized"
  ],
  "torch.ao.quantization.fx.fuse": [
    "ABC",
    "Any",
    "Callable",
    "DefaultFuseHandler",
    "Dict",
    "FuseHandler",
    "FusedGraphModule",
    "Graph",
    "GraphModule",
    "List",
    "MatchAllNode",
    "Node",
    "NodePattern",
    "Optional",
    "Pattern",
    "Tuple",
    "Union",
    "abstractmethod",
    "get_fuser_method_mapping",
    "get_fuser_method_new",
    "get_fusion_pattern_to_extra_inputs_getter",
    "get_fusion_pattern_to_fuse_handler_cls",
    "get_fusion_pattern_to_root_node_getter",
    "get_native_backend_config_dict",
    "is_match",
    "map_arg",
    "sorted_patterns_dict"
  ],
  "torch.ao.quantization.fx.fusion_patterns": [
    "ABC",
    "Any",
    "Callable",
    "Dict",
    "Graph",
    "List",
    "MatchAllNode",
    "Node",
    "NodePattern",
    "Optional",
    "Pattern",
    "Union",
    "abstractmethod",
    "get_fuser_method_new"
  ],
  "torch.ao.quantization.fx.graph_module": [
    "Any",
    "Dict",
    "Graph",
    "GraphModule",
    "Set",
    "Union"
  ],
  "torch.ao.quantization.fx.lower_to_fbgemm": [
    "Dict",
    "QConfigAny",
    "QuantizedGraphModule",
    "Tuple"
  ],
  "torch.ao.quantization.fx.match_utils": [
    "Any",
    "Callable",
    "Dict",
    "Graph",
    "List",
    "MatchAllNode",
    "MatchResult",
    "Node",
    "Optional",
    "Pattern",
    "QConfigAny",
    "QuantizeHandler",
    "Set",
    "Tuple",
    "is_observed_standalone_module"
  ],
  "torch.ao.quantization.fx.pattern_utils": [
    "Any",
    "Dict",
    "FixedQParamsFakeQuantize",
    "List",
    "MatchResult",
    "Node",
    "ObserverBase",
    "Optional",
    "OrderedDict",
    "Pattern",
    "QConfigAny",
    "QuantizeHandler",
    "Tuple"
  ],
  "torch.ao.quantization.fx.prepare": [
    "Any",
    "Argument",
    "Callable",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "MatchResult",
    "Node",
    "NodePattern",
    "ObservedGraphModule",
    "ObservedStandaloneGraphModule",
    "ObserverBase",
    "Optional",
    "Pattern",
    "QConfigAny",
    "QuantizeHandler",
    "Set",
    "Tuple",
    "Union",
    "activation_is_int8_quantized",
    "activation_is_statically_quantized",
    "all_node_args_have_no_tensors",
    "assert_and_get_unique_device",
    "convert",
    "convert_dict_to_ordered_dict",
    "defaultdict",
    "find_matches",
    "generate_qconfig_map",
    "get_custom_module_class_keys",
    "get_flattened_qconfig_dict",
    "get_fusion_pattern_to_root_node_getter",
    "get_module_to_qat_module",
    "get_native_backend_config_dict",
    "get_new_attr_name_with_prefix",
    "get_non_observable_arg_indexes_and_types",
    "get_pattern_to_dtype_configs",
    "get_pattern_to_input_type_to_index",
    "get_pattern_to_quantize_handlers",
    "get_qconfig_dtypes",
    "get_standalone_module_configs",
    "get_swapped_custom_module_class",
    "is_activation_post_process",
    "is_equalization_observer",
    "is_reuse_input_qconfig",
    "node_supports_equalization",
    "propagate_qconfig_",
    "sorted_patterns_dict",
    "update_qconfig_for_fusion",
    "update_qconfig_for_qat"
  ],
  "torch.ao.quantization.fx.qconfig_utils": [
    "Any",
    "Callable",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "Optional",
    "QConfig",
    "QConfigAny",
    "Set",
    "Tuple",
    "add_module_to_qconfig_obs_ctr",
    "defaultdict",
    "get_object_type_qconfig",
    "get_qconfig_dtypes",
    "is_activation_post_process",
    "maybe_adjust_qconfig_for_module_type_or_name",
    "qconfig_equals"
  ],
  "torch.ao.quantization.fx.quantization_patterns": [
    "ABC",
    "Any",
    "Callable",
    "Dict",
    "Node",
    "NodePattern",
    "Optional",
    "Pattern",
    "all_node_args_have_no_tensors"
  ],
  "torch.ao.quantization.fx.quantization_types": [
    "Any",
    "Node",
    "NodePattern",
    "Pattern",
    "QuantizerCls",
    "Tuple",
    "Union"
  ],
  "torch.ao.quantization.fx.utils": [
    "Any",
    "Callable",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "Node",
    "Optional",
    "Set",
    "Tuple",
    "Type",
    "Union",
    "is_activation_post_process",
    "is_per_channel",
    "is_per_tensor",
    "map_arg",
    "namedtuple"
  ],
  "torch.ao.quantization.observer": [
    "ABC",
    "ABCMeta",
    "Any",
    "Dict",
    "List",
    "Optional",
    "OrderedDict",
    "Tuple",
    "Union",
    "abstractmethod",
    "calculate_qmin_qmax",
    "check_min_max_valid",
    "partial"
  ],
  "torch.ao.quantization.qconfig": [
    "Any",
    "FakeQuantize",
    "FakeQuantizeBase",
    "FusedMovingAvgObsFakeQuantize",
    "HistogramObserver",
    "MovingAverageMinMaxObserver",
    "NoopObserver",
    "Optional",
    "PlaceholderObserver",
    "QConfigAny",
    "ReuseInputObserver",
    "default_debug_observer",
    "default_dynamic_fake_quant",
    "default_dynamic_quant_observer",
    "default_embedding_fake_quant",
    "default_embedding_fake_quant_4bit",
    "default_fake_quant",
    "default_float_qparams_observer",
    "default_float_qparams_observer_4bit",
    "default_fused_act_fake_quant",
    "default_fused_per_channel_wt_fake_quant",
    "default_fused_wt_fake_quant",
    "default_observer",
    "default_per_channel_weight_fake_quant",
    "default_per_channel_weight_observer",
    "default_placeholder_observer",
    "default_reuse_input_observer",
    "default_weight_fake_quant",
    "default_weight_observer",
    "fused_per_channel_wt_fake_quant_range_neg_127_to_127",
    "fused_wt_fake_quant_range_neg_127_to_127",
    "namedtuple",
    "per_channel_weight_observer_range_neg_127_to_127",
    "weight_observer_range_neg_127_to_127"
  ],
  "torch.ao.quantization.qconfig_dict_utils": [
    "Any",
    "Callable",
    "Dict",
    "OrderedDict",
    "QConfigAny",
    "Union",
    "get_combined_dict",
    "get_default_qat_module_mappings"
  ],
  "torch.ao.quantization.quantization_mappings": [
    "Any",
    "Callable",
    "DeQuantStub",
    "Dict",
    "Optional",
    "QuantStub",
    "Set",
    "Union",
    "default_affine_fixed_qparams_fake_quant",
    "default_symmetric_fixed_qparams_fake_quant",
    "get_combined_dict",
    "type_before_parametrizations"
  ],
  "torch.ao.quantization.quantize": [
    "DeQuantStub",
    "QuantWrapper",
    "activation_is_memoryless",
    "add_module_to_qconfig_obs_ctr",
    "get_default_dynamic_quant_module_mappings",
    "get_default_qat_module_mappings",
    "get_default_qconfig_propagation_list",
    "get_default_static_quant_module_mappings",
    "get_default_static_quant_reference_module_mappings",
    "get_qparam_dict",
    "has_no_children_ignoring_parametrizations",
    "no_observer_set",
    "type_before_parametrizations"
  ],
  "torch.ao.quantization.quantize_jit": [
    "QConfig",
    "QuantType",
    "wrap_cpp_module"
  ],
  "torch.ao.quantization.utils": [
    "Any",
    "Callable",
    "Pattern",
    "QuantType",
    "Tuple",
    "Union",
    "is_parametrized",
    "quant_type_to_str"
  ],
  "torch.ao.sparsity.experimental.pruner.base_pruner": [
    "ActivationReconstruction",
    "BaseSparsifier",
    "BiasHook",
    "ModuleDict",
    "ModuleList",
    "PruningParametrization",
    "ZeroesParametrization",
    "fqn_to_module",
    "module_to_fqn"
  ],
  "torch.ao.sparsity.experimental.pruner.parametrization": [
    "Any",
    "List"
  ],
  "torch.ao.sparsity.scheduler.base_scheduler": [
    "BaseSparsifier",
    "wraps"
  ],
  "torch.ao.sparsity.scheduler.lambda_scheduler": [
    "BaseScheduler"
  ],
  "torch.ao.sparsity.sparsifier.base_sparsifier": [
    "Dict",
    "FakeSparsity",
    "Optional",
    "Tuple",
    "defaultdict",
    "fqn_to_module",
    "module_to_fqn"
  ],
  "torch.ao.sparsity.sparsifier.weight_norm_sparsifier": [
    "BaseSparsifier",
    "Tuple",
    "reduce"
  ],
  "torch.autograd": [
    "Any",
    "Callable",
    "DeviceType",
    "List",
    "Optional",
    "ProfilerActivity",
    "ProfilerConfig",
    "ProfilerEvent",
    "ProfilerState",
    "SavedTensor",
    "Sequence",
    "Tuple",
    "Union",
    "cast",
    "handle_torch_function",
    "has_torch_function",
    "is_tensor_like",
    "kineto_available"
  ],
  "torch.autograd.anomaly_mode": [
    "Any"
  ],
  "torch.autograd.forward_ad": [
    "Any",
    "namedtuple"
  ],
  "torch.autograd.function": [
    "Any",
    "List",
    "Optional",
    "OrderedDict",
    "with_metaclass"
  ],
  "torch.autograd.functional": [
    "List",
    "Tuple"
  ],
  "torch.autograd.grad_mode": [
    "Any",
    "Callable",
    "FuncType",
    "TypeVar",
    "cast"
  ],
  "torch.autograd.gradcheck": [
    "Callable",
    "Dict",
    "Iterable",
    "List",
    "Optional",
    "Tuple",
    "Union",
    "is_tensor_like",
    "product",
    "vmap"
  ],
  "torch.autograd.graph": [
    "Any",
    "Callable"
  ],
  "torch.autograd.profiler": [
    "Any",
    "ContextDecorator",
    "DeviceType",
    "Dict",
    "Future",
    "List",
    "Optional",
    "ProfilerActivity",
    "ProfilerConfig",
    "ProfilerState",
    "kineto_available",
    "warn"
  ],
  "torch.autograd.profiler_legacy": [
    "DeviceType",
    "EventList",
    "FunctionEvent",
    "ProfilerConfig",
    "ProfilerState",
    "warn"
  ],
  "torch.autograd.profiler_util": [
    "DeviceType",
    "Dict",
    "List",
    "Optional",
    "Tuple",
    "attrgetter",
    "defaultdict",
    "namedtuple"
  ],
  "torch.autograd.variable": [
    "ImperativeEngine",
    "with_metaclass"
  ],
  "torch.backends": [
    "contextmanager"
  ],
  "torch.backends.cuda": [
    "Union"
  ],
  "torch.cpu.amp.autocast_mode": [
    "Any"
  ],
  "torch.cuda": [
    "Any",
    "Device",
    "Dict",
    "List",
    "Optional",
    "Tuple",
    "Union",
    "classproperty"
  ],
  "torch.cuda.amp.autocast_mode": [
    "Any"
  ],
  "torch.cuda.amp.common": [
    "find_spec"
  ],
  "torch.cuda.amp.grad_scaler": [
    "Any",
    "Dict",
    "Enum",
    "List",
    "Optional",
    "Tuple",
    "amp_definitely_not_available",
    "defaultdict"
  ],
  "torch.cuda.memory": [
    "Any",
    "Device",
    "Dict",
    "Union",
    "is_initialized"
  ],
  "torch.cuda.nccl": [
    "Optional",
    "Sequence",
    "Union"
  ],
  "torch.cuda.nvtx": [
    "contextmanager"
  ],
  "torch.cuda.profiler": [
    "check_error",
    "cudart"
  ],
  "torch.cuda.random": [
    "Iterable",
    "List",
    "Tensor",
    "Union",
    "cast",
    "current_device",
    "device_count"
  ],
  "torch.distributed": [
    "AllToAllOptions",
    "AllreduceCoalescedOptions",
    "AllreduceOptions",
    "BarrierOptions",
    "BroadcastOptions",
    "BuiltinCommHookType",
    "Callable",
    "DebugLevel",
    "Dict",
    "Enum",
    "FileStore",
    "GatherOptions",
    "GradBucket",
    "HashStore",
    "Logger",
    "Optional",
    "PrefixStore",
    "ProcessGroup",
    "ProcessGroupGloo",
    "ProcessGroupMPI",
    "ProcessGroupNCCL",
    "ReduceOp",
    "ReduceOptions",
    "ReduceScatterOptions",
    "Reducer",
    "ScatterOptions",
    "Store",
    "TCPStore",
    "Tuple",
    "Union",
    "get_debug_level",
    "set_debug_level",
    "set_debug_level_from_env",
    "timedelta"
  ],
  "torch.distributed.algorithms.ddp_comm_hooks": [
    "DistributedDataParallel",
    "Enum",
    "partial"
  ],
  "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [
    "Any"
  ],
  "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [
    "Any",
    "Callable"
  ],
  "torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks": [
    "Any",
    "Callable"
  ],
  "torch.distributed.algorithms.join": [
    "ABC",
    "Any",
    "List",
    "NamedTuple",
    "Optional",
    "TracebackType",
    "Type",
    "abstractmethod"
  ],
  "torch.distributed.algorithms.model_averaging.averagers": [
    "Dict",
    "Iterable",
    "Union",
    "ABC",
    "abstractmethod"
  ],
  "torch.distributed.algorithms.model_averaging.utils": [
    "Dict",
    "Iterable",
    "Union",
    "Iterator"
  ],
  "torch.distributed.autograd": [
    "DistAutogradContext",
    "backward",
    "get_gradients"
  ],
  "torch.distributed.distributed_c10d": [
    "AllToAllOptions",
    "AllreduceCoalescedOptions",
    "AllreduceOptions",
    "BarrierOptions",
    "BroadcastOptions",
    "Callable",
    "DebugLevel",
    "Dict",
    "GatherOptions",
    "Optional",
    "PrefixStore",
    "ProcessGroup",
    "ProcessGroupGloo",
    "ProcessGroupMPI",
    "ProcessGroupNCCL",
    "ReduceOp",
    "ReduceOptions",
    "ReduceScatterOptions",
    "ScatterOptions",
    "Store",
    "Tuple",
    "Union",
    "get_debug_level",
    "register_rendezvous_handler",
    "rendezvous",
    "timedelta"
  ],
  "torch.distributed.elastic.agent.server.api": [
    "Any",
    "Callable",
    "Dict",
    "Enum",
    "Event",
    "EventSource",
    "List",
    "Optional",
    "ProcessFailure",
    "SignalException",
    "Std",
    "Store",
    "Tuple",
    "Union",
    "closing",
    "dataclass",
    "field",
    "get_logger",
    "prof",
    "put_metric",
    "record"
  ],
  "torch.distributed.elastic.events": [
    "Dict",
    "Enum",
    "EventMetadataValue",
    "Optional"
  ],
  "torch.distributed.elastic.events.api": [
    "Dict",
    "Enum",
    "EventMetadataValue",
    "Optional",
    "Union",
    "asdict",
    "dataclass",
    "field"
  ],
  "torch.distributed.elastic.events.handlers": [
    "Dict"
  ],
  "torch.distributed.elastic.metrics": [
    "Optional"
  ],
  "torch.distributed.elastic.metrics.api": [
    "Dict",
    "Optional",
    "namedtuple",
    "wraps"
  ],
  "torch.distributed.elastic.multiprocessing": [
    "Callable",
    "Dict",
    "Tuple",
    "Union",
    "get_logger"
  ],
  "torch.distributed.elastic.multiprocessing.api": [
    "Any",
    "Callable",
    "Dict",
    "FrameType",
    "IntFlag",
    "Optional",
    "ProcessFailure",
    "Set",
    "TailLog",
    "Tuple",
    "Union",
    "dataclass",
    "field",
    "nullcontext",
    "record",
    "redirect_stderr",
    "redirect_stdout"
  ],
  "torch.distributed.elastic.multiprocessing.errors": [
    "Any",
    "Callable",
    "Dict",
    "GlobalRank",
    "JSON",
    "List",
    "Optional",
    "Template",
    "Tuple",
    "TypeVar",
    "dataclass",
    "datetime",
    "field",
    "get_logger",
    "wraps"
  ],
  "torch.distributed.elastic.multiprocessing.errors.error_handler": [
    "Optional"
  ],
  "torch.distributed.elastic.multiprocessing.errors.handlers": [
    "ErrorHandler"
  ],
  "torch.distributed.elastic.multiprocessing.redirects": [
    "contextmanager",
    "partial",
    "redirect_stderr",
    "redirect_stdout"
  ],
  "torch.distributed.elastic.multiprocessing.tail_log": [
    "Dict",
    "Event",
    "Future",
    "List",
    "TextIO",
    "ThreadPoolExecutor"
  ],
  "torch.distributed.elastic.rendezvous": [
    "ABC",
    "Any",
    "Callable",
    "Dict",
    "Optional",
    "RendezvousHandlerCreator",
    "Store",
    "Tuple",
    "abstractmethod"
  ],
  "torch.distributed.elastic.rendezvous.api": [
    "ABC",
    "Any",
    "Callable",
    "Dict",
    "Optional",
    "RendezvousHandlerCreator",
    "Store",
    "Tuple",
    "abstractmethod"
  ],
  "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [
    "ABC",
    "Any",
    "Callable",
    "Dict",
    "Enum",
    "List",
    "NodeState",
    "Optional",
    "PrefixStore",
    "RendezvousClosedError",
    "RendezvousError",
    "RendezvousHandler",
    "RendezvousParameters",
    "RendezvousStateError",
    "RendezvousTimeoutError",
    "Set",
    "Store",
    "Token",
    "Tuple",
    "abstractmethod",
    "cast",
    "construct_and_record_rdzv_event",
    "dataclass",
    "datetime",
    "timedelta"
  ],
  "torch.distributed.elastic.rendezvous.registry": [
    "RendezvousHandler",
    "RendezvousParameters",
    "create_handler"
  ],
  "torch.distributed.elastic.rendezvous.utils": [
    "Any",
    "Callable",
    "Dict",
    "Event",
    "Optional",
    "Thread",
    "Tuple",
    "Union",
    "timedelta"
  ],
  "torch.distributed.elastic.timer.api": [
    "Any",
    "Dict",
    "List",
    "Optional",
    "Set",
    "contextmanager",
    "getframeinfo",
    "stack"
  ],
  "torch.distributed.elastic.timer.local_timer": [
    "Any",
    "Dict",
    "Empty",
    "List",
    "RequestQueue",
    "Set",
    "TimerClient",
    "TimerRequest",
    "TimerServer",
    "Tuple"
  ],
  "torch.distributed.elastic.utils.api": [
    "Any",
    "List",
    "Template"
  ],
  "torch.distributed.elastic.utils.data.elastic_distributed_sampler": [
    "DistributedSampler"
  ],
  "torch.distributed.elastic.utils.logging": [
    "Optional",
    "get_log_level"
  ],
  "torch.distributed.elastic.utils.store": [
    "List",
    "timedelta"
  ],
  "torch.distributed.fsdp.flatten_params_wrapper": [
    "Any",
    "Dict",
    "Generator",
    "Iterator",
    "List",
    "NamedTuple",
    "Optional",
    "ParamOffset",
    "Sequence",
    "SharedParamInfo",
    "Tensor",
    "Tuple",
    "Union",
    "accumulate"
  ],
  "torch.distributed.fsdp.fully_sharded_data_parallel": [
    "Any",
    "Callable",
    "Dict",
    "Enum",
    "FlatParameter",
    "FlattenParamsWrapper",
    "Generator",
    "Iterable",
    "Iterator",
    "List",
    "NamedTuple",
    "Optional",
    "Parameter",
    "ProcessGroup",
    "Set",
    "Shard",
    "ShardedTensor",
    "Tuple",
    "Union",
    "Variable",
    "auto",
    "cast",
    "contextmanager",
    "dataclass",
    "init_from_local_shards"
  ],
  "torch.distributed.fsdp.optim_utils": [
    "Any",
    "Dict",
    "FlatParameter",
    "Iterable",
    "Iterator",
    "List",
    "Optional",
    "Union"
  ],
  "torch.distributed.fsdp.utils": [
    "Any",
    "Callable",
    "Dict",
    "List",
    "OrderedDict",
    "Set",
    "Tuple",
    "Union"
  ],
  "torch.distributed.fsdp.wrap": [
    "Any",
    "Callable",
    "Dict",
    "Generator",
    "Optional",
    "Set",
    "Tuple",
    "Type",
    "cast"
  ],
  "torch.distributed.launcher.api": [
    "Any",
    "Callable",
    "ChildFailedError",
    "Dict",
    "List",
    "LocalElasticAgent",
    "Optional",
    "RendezvousParameters",
    "SignalException",
    "Std",
    "Tuple",
    "Union",
    "WorkerSpec",
    "dataclass",
    "field",
    "get_logger",
    "parse_rendezvous_endpoint"
  ],
  "torch.distributed.nn": [
    "Function"
  ],
  "torch.distributed.nn.api.remote_module": [
    "Any",
    "Callable",
    "Dict",
    "Iterator",
    "List",
    "Module",
    "Optional",
    "Parameter",
    "RemovableHandle",
    "Set",
    "Tensor",
    "Tuple",
    "Type",
    "TypeVar",
    "Union",
    "device",
    "dtype"
  ],
  "torch.distributed.nn.functional": [
    "Function"
  ],
  "torch.distributed.nn.jit.instantiator": [
    "Optional",
    "get_remote_module_template"
  ],
  "torch.distributed.optim.functional_adadelta": [
    "Dict",
    "List",
    "Optional",
    "Tensor"
  ],
  "torch.distributed.optim.functional_adagrad": [
    "Dict",
    "List",
    "Optional",
    "Tensor"
  ],
  "torch.distributed.optim.functional_adam": [
    "Dict",
    "List",
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.distributed.optim.functional_adamax": [
    "Dict",
    "List",
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.distributed.optim.functional_adamw": [
    "Dict",
    "List",
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.distributed.optim.functional_rmsprop": [
    "Dict",
    "List",
    "Optional",
    "Tensor"
  ],
  "torch.distributed.optim.functional_rprop": [
    "Dict",
    "List",
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.distributed.optim.functional_sgd": [
    "Dict",
    "List",
    "Optional",
    "Tensor"
  ],
  "torch.distributed.optim.optimizer": [
    "List",
    "Lock",
    "Optional",
    "RRef",
    "Tensor",
    "defaultdict"
  ],
  "torch.distributed.optim.utils": [
    "Type"
  ],
  "torch.distributed.optim.zero_redundancy_optimizer": [
    "Any",
    "Callable",
    "Dict",
    "Join",
    "JoinHook",
    "Joinable",
    "List",
    "Optimizer",
    "Optional",
    "Set",
    "Type",
    "Union",
    "chain"
  ],
  "torch.distributed.pipeline.sync.batchnorm": [
    "Optional",
    "Tensor",
    "TypeVar",
    "batch_norm",
    "cast",
    "is_recomputing"
  ],
  "torch.distributed.pipeline.sync.checkpoint": [
    "Any",
    "Batch",
    "Deque",
    "Generator",
    "List",
    "Optional",
    "Protocol",
    "RNGStates",
    "Recomputed",
    "Sequence",
    "Tensor",
    "TensorOrTensors",
    "Tensors",
    "Tuple",
    "Union",
    "contextmanager",
    "deque",
    "fork",
    "get_phony",
    "join"
  ],
  "torch.distributed.pipeline.sync.copy": [
    "AbstractStream",
    "Deque",
    "List",
    "Optional",
    "Sequence",
    "Tensor",
    "Tensors",
    "Tuple",
    "current_stream",
    "deque",
    "get_device",
    "record_stream",
    "use_stream",
    "wait_stream"
  ],
  "torch.distributed.pipeline.sync.dependency": [
    "List",
    "Tensor",
    "Tuple",
    "get_phony"
  ],
  "torch.distributed.pipeline.sync.microbatch": [
    "Any",
    "Callable",
    "Function",
    "List",
    "Sequence",
    "Tensor",
    "TensorOrTensors",
    "Tensors",
    "Union",
    "cast"
  ],
  "torch.distributed.pipeline.sync.phony": [
    "Dict",
    "List",
    "Tensor",
    "Tuple",
    "default_stream",
    "use_stream"
  ],
  "torch.distributed.pipeline.sync.pipe": [
    "AbstractStream",
    "Any",
    "DeferredBatchNorm",
    "Device",
    "Devices",
    "Iterable",
    "List",
    "Module",
    "NamedModules",
    "Optional",
    "OrderedDict",
    "RRef",
    "Sequence",
    "Tensor",
    "TensorOrTensors",
    "Tensors",
    "Tuple",
    "Union",
    "cast",
    "inspect_skip_layout",
    "new_stream",
    "verify_skippables"
  ],
  "torch.distributed.pipeline.sync.pipeline": [
    "AbstractStream",
    "Batch",
    "Checkpointing",
    "Copy",
    "ExcInfo",
    "InQueue",
    "Iterable",
    "List",
    "Optional",
    "OutQueue",
    "Queue",
    "Sequence",
    "SkipLayout",
    "SkipTrackerThroughPotals",
    "Task",
    "Tensor",
    "TensorOrTensors",
    "Tensors",
    "TracebackType",
    "Tuple",
    "Type",
    "Union",
    "Wait",
    "cast",
    "create_workers",
    "current_stream",
    "fork",
    "join",
    "record_function",
    "use_device",
    "use_skip_tracker"
  ],
  "torch.distributed.pipeline.sync.skip.layout": [
    "Dict",
    "Iterable",
    "List",
    "Namespace",
    "Tuple"
  ],
  "torch.distributed.pipeline.sync.skip.namespace": [
    "Any",
    "total_ordering"
  ],
  "torch.distributed.pipeline.sync.skip.portal": [
    "AbstractStream",
    "Copy",
    "CopyContext",
    "List",
    "Optional",
    "Tensor",
    "Tuple",
    "get_device",
    "get_phony"
  ],
  "torch.distributed.pipeline.sync.skip.skippable": [
    "Any",
    "Batch",
    "Callable",
    "ClassVar",
    "Dict",
    "FrozenSet",
    "Generator",
    "Iterable",
    "List",
    "Namespace",
    "Optional",
    "Sequence",
    "Set",
    "SkippableModule",
    "StashPop",
    "StashPopGenerator",
    "Tensor",
    "TensorOrTensors",
    "Tensors",
    "Tuple",
    "Type",
    "TypeVar",
    "Union",
    "cast",
    "current_skip_tracker"
  ],
  "torch.distributed.pipeline.sync.skip.tracker": [
    "AbstractStream",
    "Batch",
    "Dict",
    "Generator",
    "List",
    "Namespace",
    "Optional",
    "Portal",
    "SkipLayout",
    "Tensor",
    "Tuple",
    "contextmanager",
    "fork",
    "is_checkpointing",
    "join"
  ],
  "torch.distributed.pipeline.sync.stream": [
    "AbstractStream",
    "Generator",
    "List",
    "Union",
    "cast",
    "contextmanager"
  ],
  "torch.distributed.pipeline.sync.worker": [
    "AbstractStream",
    "Batch",
    "Callable",
    "Dict",
    "ExcInfo",
    "Generator",
    "InQueue",
    "List",
    "Optional",
    "OutQueue",
    "Queue",
    "Thread",
    "TracebackType",
    "Tuple",
    "Type",
    "Union",
    "cast",
    "contextmanager",
    "use_device",
    "use_stream"
  ],
  "torch.distributed.remote_device": [
    "Optional",
    "Union"
  ],
  "torch.distributed.rendezvous": [
    "Dict",
    "FileStore",
    "Iterable",
    "Optional",
    "PrefixStore",
    "Store",
    "TCPStore",
    "Tuple",
    "Union",
    "cast",
    "timedelta",
    "urlparse",
    "urlunparse"
  ],
  "torch.distributed.rpc": [
    "Any",
    "Dict",
    "Future",
    "Generator",
    "Generic",
    "GenericWithOneTypeVar",
    "PyRRef",
    "RemoteProfilerManager",
    "RpcAgent",
    "RpcBackendOptions",
    "Set",
    "Store",
    "TensorPipeAgent",
    "Tuple",
    "TypeVar",
    "WorkerInfo",
    "enable_gil_profiling",
    "get_rpc_timeout",
    "method",
    "timedelta",
    "urlparse"
  ],
  "torch.distributed.rpc.api": [
    "Any",
    "Dict",
    "Future",
    "Generic",
    "GenericWithOneTypeVar",
    "PyRRef",
    "PythonUDF",
    "RPCExecMode",
    "RemoteProfilerManager",
    "Set",
    "TypeVar",
    "WorkerInfo",
    "get_rpc_timeout",
    "method"
  ],
  "torch.distributed.rpc.backend_registry": [
    "Dict",
    "List",
    "Set",
    "Tuple"
  ],
  "torch.distributed.rpc.constants": [
    "timedelta"
  ],
  "torch.distributed.rpc.internal": [
    "Enum"
  ],
  "torch.distributed.rpc.options": [
    "DeviceType",
    "Dict",
    "List",
    "Optional",
    "Union"
  ],
  "torch.distributed.rpc.server_process_global_profiler": [
    "profile"
  ],
  "torch.distributions.bernoulli": [
    "ExponentialFamily",
    "Number",
    "binary_cross_entropy_with_logits",
    "broadcast_all",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.beta": [
    "Dirichlet",
    "ExponentialFamily",
    "Number",
    "Real",
    "broadcast_all"
  ],
  "torch.distributions.binomial": [
    "Distribution",
    "broadcast_all",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.categorical": [
    "Distribution",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.cauchy": [
    "Distribution",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.chi2": [
    "Gamma"
  ],
  "torch.distributions.continuous_bernoulli": [
    "ExponentialFamily",
    "Number",
    "binary_cross_entropy_with_logits",
    "broadcast_all",
    "clamp_probs",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.dirichlet": [
    "ExponentialFamily",
    "Function",
    "once_differentiable"
  ],
  "torch.distributions.distribution": [
    "Any",
    "Dict",
    "Optional",
    "lazy_property"
  ],
  "torch.distributions.exp_family": [
    "Distribution"
  ],
  "torch.distributions.exponential": [
    "ExponentialFamily",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.fishersnedecor": [
    "Distribution",
    "Gamma",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.gamma": [
    "ExponentialFamily",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.geometric": [
    "Distribution",
    "Number",
    "binary_cross_entropy_with_logits",
    "broadcast_all",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.gumbel": [
    "AffineTransform",
    "ExpTransform",
    "Number",
    "TransformedDistribution",
    "Uniform",
    "broadcast_all"
  ],
  "torch.distributions.half_cauchy": [
    "AbsTransform",
    "Cauchy",
    "TransformedDistribution"
  ],
  "torch.distributions.half_normal": [
    "AbsTransform",
    "Normal",
    "TransformedDistribution"
  ],
  "torch.distributions.independent": [
    "Dict",
    "Distribution"
  ],
  "torch.distributions.kl": [
    "Bernoulli",
    "Beta",
    "Binomial",
    "Callable",
    "Categorical",
    "Cauchy",
    "ContinuousBernoulli",
    "Dict",
    "Dirichlet",
    "Distribution",
    "Exponential",
    "ExponentialFamily",
    "Gamma",
    "Geometric",
    "Gumbel",
    "HalfNormal",
    "Independent",
    "Laplace",
    "LowRankMultivariateNormal",
    "MultivariateNormal",
    "Normal",
    "OneHotCategorical",
    "Pareto",
    "Poisson",
    "TransformedDistribution",
    "Tuple",
    "Type",
    "Uniform",
    "total_ordering"
  ],
  "torch.distributions.kumaraswamy": [
    "AffineTransform",
    "PowerTransform",
    "TransformedDistribution",
    "Uniform",
    "broadcast_all"
  ],
  "torch.distributions.laplace": [
    "Distribution",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.lkj_cholesky": [
    "Beta",
    "Distribution",
    "broadcast_all"
  ],
  "torch.distributions.log_normal": [
    "ExpTransform",
    "Normal",
    "TransformedDistribution"
  ],
  "torch.distributions.logistic_normal": [
    "Normal",
    "StickBreakingTransform",
    "TransformedDistribution"
  ],
  "torch.distributions.lowrank_multivariate_normal": [
    "Distribution",
    "lazy_property"
  ],
  "torch.distributions.mixture_same_family": [
    "Categorical",
    "Dict",
    "Distribution"
  ],
  "torch.distributions.multinomial": [
    "Binomial",
    "Categorical",
    "Distribution",
    "broadcast_all"
  ],
  "torch.distributions.multivariate_normal": [
    "Distribution",
    "lazy_property"
  ],
  "torch.distributions.negative_binomial": [
    "Distribution",
    "broadcast_all",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.normal": [
    "ExponentialFamily",
    "Number",
    "Real",
    "broadcast_all"
  ],
  "torch.distributions.one_hot_categorical": [
    "Categorical",
    "Distribution"
  ],
  "torch.distributions.pareto": [
    "AffineTransform",
    "ExpTransform",
    "Exponential",
    "TransformedDistribution",
    "broadcast_all"
  ],
  "torch.distributions.poisson": [
    "ExponentialFamily",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.relaxed_bernoulli": [
    "Distribution",
    "Number",
    "SigmoidTransform",
    "TransformedDistribution",
    "broadcast_all",
    "clamp_probs",
    "lazy_property",
    "logits_to_probs",
    "probs_to_logits"
  ],
  "torch.distributions.relaxed_categorical": [
    "Categorical",
    "Distribution",
    "ExpTransform",
    "TransformedDistribution",
    "broadcast_all",
    "clamp_probs"
  ],
  "torch.distributions.studentT": [
    "Chi2",
    "Distribution",
    "broadcast_all"
  ],
  "torch.distributions.transformed_distribution": [
    "ComposeTransform",
    "Dict",
    "Distribution",
    "Independent",
    "Transform"
  ],
  "torch.distributions.transforms": [
    "List",
    "broadcast_all",
    "lazy_property",
    "pad",
    "softplus",
    "tril_matrix_to_vec",
    "vec_to_tril_matrix"
  ],
  "torch.distributions.uniform": [
    "Distribution",
    "Number",
    "broadcast_all"
  ],
  "torch.distributions.utils": [
    "Any",
    "Dict",
    "Number",
    "is_tensor_like",
    "update_wrapper"
  ],
  "torch.distributions.von_mises": [
    "Distribution",
    "broadcast_all",
    "lazy_property"
  ],
  "torch.distributions.weibull": [
    "AffineTransform",
    "Exponential",
    "PowerTransform",
    "TransformedDistribution",
    "broadcast_all"
  ],
  "torch.distributions.wishart": [
    "ExponentialFamily",
    "Number",
    "Union",
    "lazy_property"
  ],
  "torch.fft": [
    "Tensor",
    "fft",
    "fft2",
    "fftfreq",
    "fftn",
    "fftshift",
    "hfft",
    "hfft2",
    "hfftn",
    "ifft",
    "ifft2",
    "ifftn",
    "ifftshift",
    "ihfft",
    "ihfft2",
    "ihfftn",
    "irfft",
    "irfft2",
    "irfftn",
    "rfft",
    "rfft2",
    "rfftfreq",
    "rfftn"
  ],
  "torch.functional": [
    "Any",
    "List",
    "Optional",
    "Sequence",
    "Tensor",
    "Tuple",
    "Union",
    "boolean_dispatch",
    "handle_torch_function",
    "has_torch_function",
    "has_torch_function_unary",
    "has_torch_function_variadic",
    "istft",
    "overload",
    "pca_lowrank",
    "svd_lowrank"
  ],
  "torch.futures": [
    "Callable",
    "Future",
    "Generic",
    "List",
    "Optional",
    "Type",
    "TypeVar",
    "Union",
    "cast"
  ],
  "torch.fx": [
    "ProxyableClassMeta",
    "Tracer",
    "symbolic_trace",
    "wrap"
  ],
  "torch.fx.experimental.unification.core": [
    "Iterator",
    "assoc",
    "dispatch",
    "isvar",
    "partial",
    "unify",
    "walk"
  ],
  "torch.fx.experimental.unification.dispatch": [
    "dispatch",
    "partial"
  ],
  "torch.fx.experimental.unification.more": [
    "dispatch",
    "reify",
    "unify"
  ],
  "torch.fx.experimental.unification.multipledispatch.conflict": [
    "groupby",
    "isvariadic"
  ],
  "torch.fx.experimental.unification.multipledispatch.core": [
    "Dispatcher",
    "MethodDispatcher"
  ],
  "torch.fx.experimental.unification.multipledispatch.dispatcher": [
    "AmbiguityWarning",
    "Variadic",
    "ambiguities",
    "expand_tuples",
    "isvariadic",
    "ordering",
    "super_signature",
    "warn"
  ],
  "torch.fx.experimental.unification.multipledispatch.utils": [
    "OrderedDict"
  ],
  "torch.fx.experimental.unification.multipledispatch.variadic": [
    "typename"
  ],
  "torch.fx.experimental.unification.unification_tools": [
    "Mapping",
    "reduce"
  ],
  "torch.fx.experimental.unification.variable": [
    "contextmanager",
    "dispatch",
    "hashable",
    "isvar"
  ],
  "torch.fx.graph": [
    "Any",
    "Argument",
    "Callable",
    "Dict",
    "FrozenSet",
    "List",
    "NamedTuple",
    "Node",
    "Optional",
    "Set",
    "Target",
    "TransformCodeFunc",
    "Tuple",
    "Type",
    "compatibility",
    "contextmanager",
    "dataclass",
    "map_arg"
  ],
  "torch.fx.graph_module": [
    "Any",
    "Dict",
    "Graph",
    "Importer",
    "List",
    "Optional",
    "PackageExporter",
    "PackageImporter",
    "Path",
    "PythonCode",
    "Set",
    "Type",
    "Union",
    "compatibility"
  ],
  "torch.fx.immutable_collections": [
    "Any",
    "Context",
    "Dict",
    "List",
    "Tuple",
    "compatibility"
  ],
  "torch.fx.interpreter": [
    "Any",
    "Argument",
    "Dict",
    "Graph",
    "GraphModule",
    "Iterator",
    "List",
    "Node",
    "Optional",
    "Proxy",
    "Target",
    "Tracer",
    "Tuple",
    "Union",
    "compatibility",
    "map_aggregate",
    "map_arg"
  ],
  "torch.fx.node": [
    "Any",
    "ArgsKwargsPair",
    "Argument",
    "BaseArgumentTypes",
    "Callable",
    "Dict",
    "List",
    "Optional",
    "Set",
    "Target",
    "Tuple",
    "Union",
    "compatibility",
    "immutable_dict",
    "immutable_list",
    "normalize_function",
    "normalize_module"
  ],
  "torch.fx.operator_schemas": [
    "Any",
    "Callable",
    "Dict",
    "List",
    "NamedTuple",
    "OpOverload",
    "OpOverloadPacket",
    "Optional",
    "Tuple",
    "cast",
    "compatibility"
  ],
  "torch.fx.passes.graph_drawer": [
    "Any",
    "Dict",
    "TensorMetadata",
    "chain",
    "compatibility"
  ],
  "torch.fx.passes.graph_manipulation": [
    "Any",
    "Argument",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "NamedTuple",
    "Node",
    "Optional",
    "ShapeProp",
    "Target",
    "Tuple",
    "compatibility",
    "lift_lowering_attrs_to_nodes",
    "map_aggregate",
    "map_arg"
  ],
  "torch.fx.passes.net_min_base": [
    "Any",
    "Callable",
    "Dict",
    "FxNetAccFusionsFinder",
    "Names",
    "NodeList",
    "NodeSet",
    "Optional",
    "ShapeProp",
    "TensorOrTensors",
    "Tensors",
    "Tuple",
    "compatibility",
    "dataclass",
    "map_arg",
    "split_by_tags"
  ],
  "torch.fx.passes.operator_support": [
    "IsNodeSupported",
    "SupportDict",
    "SupportedArgumentDTypes",
    "TargetTypeName",
    "TensorMetadata",
    "compatibility",
    "get_node_target"
  ],
  "torch.fx.passes.param_fetch": [
    "Any",
    "Callable",
    "Dict",
    "GraphModule",
    "List",
    "Tuple",
    "Type",
    "compatibility"
  ],
  "torch.fx.passes.shape_prop": [
    "Any",
    "Dict",
    "NamedTuple",
    "Node",
    "Optional",
    "Tuple",
    "compatibility",
    "map_aggregate"
  ],
  "torch.fx.passes.split_module": [
    "Any",
    "Callable",
    "Dict",
    "GraphModule",
    "List",
    "Optional",
    "compatibility"
  ],
  "torch.fx.passes.split_utils": [
    "Dict",
    "List",
    "NodeList",
    "NodeSet",
    "Optional",
    "compatibility",
    "dataclass",
    "field",
    "map_arg"
  ],
  "torch.fx.passes.splitter_base": [
    "Any",
    "Dict",
    "FxGraphDrawer",
    "FxNetAccFusionsFinder",
    "Iterable",
    "List",
    "NamedTuple",
    "NodeList",
    "NodeSet",
    "OperatorSupportBase",
    "Optional",
    "Sequence",
    "ShapeProp",
    "Tensors",
    "Tuple",
    "compatibility",
    "dataclass",
    "defaultdict",
    "get_node_target",
    "get_size_of_node",
    "is_node_output_tensor",
    "map_arg",
    "split_by_tags"
  ],
  "torch.fx.passes.tools_common": [
    "Any",
    "Dict",
    "List",
    "Mapping",
    "Names",
    "NodeList",
    "NodeSet",
    "Set",
    "TensorOrTensors",
    "Tensors",
    "Tuple",
    "Union",
    "compatibility",
    "dataclass"
  ],
  "torch.fx.proxy": [
    "Any",
    "Argument",
    "Callable",
    "Dict",
    "Graph",
    "Iterable",
    "Iterator",
    "Node",
    "Optional",
    "Target",
    "Tuple",
    "check_for_mutable_operation",
    "compatibility",
    "map_aggregate"
  ],
  "torch.fx.subgraph_rewriter": [
    "Callable",
    "Dict",
    "Graph",
    "GraphModule",
    "List",
    "NamedTuple",
    "Node",
    "Optional",
    "Set",
    "compatibility",
    "symbolic_trace"
  ],
  "torch.hub": [
    "HTTPError",
    "Path",
    "Request",
    "tqdm",
    "urlopen",
    "urlparse"
  ],
  "torch.jit": [
    "Final",
    "Iterator",
    "contextmanager",
    "export",
    "ignore",
    "is_scripting",
    "last_executed_optimized_graph",
    "set_module",
    "unused",
    "Attribute",
    "ONNXTracedModule",
    "RecursiveScriptClass",
    "RecursiveScriptModule",
    "ScriptModule",
    "ScriptWarning",
    "TopLevelTracedModule",
    "TracedModule",
    "TracerWarning",
    "TracingCheckError",
    "fork",
    "freeze",
    "fuser",
    "interface",
    "is_tracing",
    "jit_module_from_flatbuffer",
    "load",
    "optimize_for_inference",
    "optimized_execution",
    "run_frozen_optimizations",
    "save",
    "save_jit_module_to_flatbuffer",
    "script",
    "script_method",
    "set_fusion_strategy",
    "trace",
    "trace_module",
    "wait"
  ],
  "torch.jit.annotations": [
    "Any",
    "AnyType",
    "BoolType",
    "ComplexType",
    "DeviceObjType",
    "Dict",
    "DictType",
    "EnumType",
    "FloatType",
    "Future",
    "FutureType",
    "IntType",
    "InterfaceType",
    "List",
    "ListType",
    "NoneType",
    "NumberType",
    "OpOverloadPacket",
    "Optional",
    "OptionalType",
    "RRef",
    "RRefType",
    "StreamObjType",
    "StringType",
    "TensorType",
    "Tuple",
    "TupleType",
    "Type",
    "Union",
    "UnionType",
    "dedent",
    "get_source_lines_and_file",
    "is_dict",
    "is_future",
    "is_ignored_fn",
    "is_list",
    "is_optional",
    "is_rref",
    "is_tuple",
    "is_union"
  ],
  "torch.jit.frontend": [
    "monkeytype_trace",
    "Apply",
    "Assert",
    "Assign",
    "Attribute",
    "AugAssign",
    "BinOp",
    "Break",
    "ClassDef",
    "Const",
    "Continue",
    "Decl",
    "Def",
    "Delete",
    "DictComp",
    "DictLiteral",
    "Dots",
    "EmptyTypeAnnotation",
    "ExprStmt",
    "FalseLiteral",
    "For",
    "FunctionModifiers",
    "Ident",
    "If",
    "List",
    "ListComp",
    "ListLiteral",
    "NoneLiteral",
    "Param",
    "Pass",
    "Property",
    "Raise",
    "Return",
    "Select",
    "SliceExpr",
    "Starred",
    "Stmt",
    "StringLiteral",
    "Subscript",
    "TernaryIf",
    "TrueLiteral",
    "Tuple",
    "TupleLiteral",
    "UnaryOp",
    "Var",
    "While",
    "With",
    "WithItem",
    "dedent",
    "get_qualified_name",
    "get_source_lines_and_file",
    "is_static_fn",
    "make_source_context",
    "namedtuple",
    "parse_def",
    "should_drop"
  ],
  "torch.linalg": [
    "LinAlgError",
    "Tensor",
    "cholesky",
    "cholesky_ex",
    "cond",
    "cross",
    "det",
    "diagonal",
    "eig",
    "eigh",
    "eigvals",
    "eigvalsh",
    "householder_product",
    "inv",
    "inv_ex",
    "lstsq",
    "lu_factor",
    "lu_factor_ex",
    "matmul",
    "matrix_exp",
    "matrix_norm",
    "matrix_power",
    "matrix_rank",
    "multi_dot",
    "norm",
    "pinv",
    "qr",
    "slogdet",
    "solve",
    "solve_triangular",
    "svd",
    "svdvals",
    "tensorinv",
    "tensorsolve",
    "vector_norm"
  ],
  "torch.multiprocessing": [
    "Array",
    "AuthenticationError",
    "Barrier",
    "BoundedSemaphore",
    "BufferTooShort",
    "Condition",
    "Event",
    "JoinableQueue",
    "Lock",
    "Manager",
    "Pipe",
    "Pool",
    "Process",
    "ProcessError",
    "Queue",
    "RLock",
    "RawArray",
    "RawValue",
    "Semaphore",
    "SimpleQueue",
    "TimeoutError",
    "Value",
    "active_children",
    "allow_connection_pickling",
    "cpu_count",
    "current_process",
    "freeze_support",
    "get_all_start_methods",
    "get_context",
    "get_logger",
    "get_start_method",
    "log_to_stderr",
    "parent_process",
    "set_executable",
    "set_forkserver_preload",
    "set_start_method"
  ],
  "torch.multiprocessing.reductions": [
    "ForkingPickler",
    "Union",
    "check_serializing_named_tensor",
    "register_after_fork"
  ],
  "torch.multiprocessing.spawn": [
    "Optional"
  ],
  "torch.nn.common_types": [
    "Optional",
    "Tensor",
    "Tuple",
    "TypeVar",
    "Union"
  ],
  "torch.nn.functional": [
    "Callable",
    "DType",
    "List",
    "Optional",
    "Tensor",
    "Tuple",
    "Union",
    "adaptive_avg_pool1d",
    "avg_pool1d",
    "avg_pool2d",
    "avg_pool3d",
    "bilinear",
    "boolean_dispatch",
    "celu_",
    "channel_shuffle",
    "conv1d",
    "conv2d",
    "conv3d",
    "conv_tbc",
    "conv_transpose1d",
    "conv_transpose2d",
    "conv_transpose3d",
    "cosine_similarity",
    "elu_",
    "gelu",
    "handle_torch_function",
    "hardshrink",
    "hardtanh_",
    "has_torch_function",
    "has_torch_function_unary",
    "has_torch_function_variadic",
    "leaky_relu_",
    "linear",
    "logsigmoid",
    "native_channel_shuffle",
    "one_hot",
    "pairwise_distance",
    "pdist",
    "pixel_shuffle",
    "pixel_unshuffle",
    "prelu",
    "relu_",
    "rrelu_",
    "selu_",
    "softplus",
    "softshrink",
    "threshold_"
  ],
  "torch.nn.init": [
    "Tensor"
  ],
  "torch.nn.intrinsic.modules.fused": [
    "BatchNorm1d",
    "BatchNorm2d",
    "BatchNorm3d",
    "Conv1d",
    "Conv2d",
    "Conv3d",
    "Linear",
    "ReLU",
    "type_before_parametrizations"
  ],
  "torch.nn.intrinsic.qat.modules.conv_fused": [
    "Parameter",
    "TypeVar",
    "fuse_conv_bn_weights"
  ],
  "torch.nn.intrinsic.qat.modules.linear_fused": [
    "Parameter",
    "fuse_linear_bn_weights"
  ],
  "torch.nn.intrinsic.quantized.modules.conv_relu": [
    "fuse_conv_bn_weights"
  ],
  "torch.nn.modules.activation": [
    "Module",
    "NonDynamicallyQuantizableLinear",
    "Optional",
    "Parameter",
    "Tensor",
    "Tuple",
    "constant_",
    "xavier_normal_",
    "xavier_uniform_"
  ],
  "torch.nn.modules.adaptive": [
    "Linear",
    "List",
    "Module",
    "ModuleList",
    "Sequence",
    "Sequential",
    "Tensor",
    "log_softmax",
    "namedtuple"
  ],
  "torch.nn.modules.batchnorm": [
    "Any",
    "LazyModuleMixin",
    "Module",
    "Optional",
    "Parameter",
    "Tensor",
    "UninitializedBuffer",
    "UninitializedParameter",
    "sync_batch_norm"
  ],
  "torch.nn.modules.channelshuffle": [
    "Module",
    "Tensor"
  ],
  "torch.nn.modules.container": [
    "Any",
    "Dict",
    "Iterable",
    "Iterator",
    "Mapping",
    "Module",
    "Optional",
    "OrderedDict",
    "Parameter",
    "Tuple",
    "TypeVar",
    "Union",
    "chain",
    "islice",
    "overload"
  ],
  "torch.nn.modules.conv": [
    "LazyModuleMixin",
    "List",
    "Module",
    "Optional",
    "Parameter",
    "Tensor",
    "Tuple",
    "UninitializedParameter",
    "Union"
  ],
  "torch.nn.modules.distance": [
    "Module",
    "Tensor"
  ],
  "torch.nn.modules.dropout": [
    "Module",
    "Tensor"
  ],
  "torch.nn.modules.flatten": [
    "Module",
    "Tensor",
    "Tuple",
    "Union"
  ],
  "torch.nn.modules.fold": [
    "Module",
    "Tensor"
  ],
  "torch.nn.modules.instancenorm": [
    "Tensor"
  ],
  "torch.nn.modules.lazy": [
    "Protocol",
    "is_lazy"
  ],
  "torch.nn.modules.linear": [
    "LazyModuleMixin",
    "Module",
    "Parameter",
    "Tensor",
    "UninitializedParameter"
  ],
  "torch.nn.modules.loss": [
    "Callable",
    "Module",
    "Optional",
    "PairwiseDistance",
    "Tensor"
  ],
  "torch.nn.modules.module": [
    "Any",
    "Callable",
    "Dict",
    "Iterator",
    "List",
    "Mapping",
    "Optional",
    "OrderedDict",
    "Parameter",
    "RemovableHandle",
    "Set",
    "Tensor",
    "Tuple",
    "TypeVar",
    "Union",
    "device",
    "dtype",
    "namedtuple",
    "overload"
  ],
  "torch.nn.modules.normalization": [
    "List",
    "Module",
    "Parameter",
    "Size",
    "Tensor",
    "Tuple",
    "Union"
  ],
  "torch.nn.modules.padding": [
    "Module",
    "Sequence",
    "Tensor",
    "Tuple"
  ],
  "torch.nn.modules.pixelshuffle": [
    "Module",
    "Tensor"
  ],
  "torch.nn.modules.pooling": [
    "List",
    "Module",
    "Optional",
    "Tensor"
  ],
  "torch.nn.modules.rnn": [
    "List",
    "Module",
    "Optional",
    "PackedSequence",
    "Parameter",
    "Tensor",
    "Tuple",
    "overload"
  ],
  "torch.nn.modules.sparse": [
    "Module",
    "Optional",
    "Parameter",
    "Tensor"
  ],
  "torch.nn.modules.transformer": [
    "Any",
    "Callable",
    "Dropout",
    "LayerNorm",
    "Linear",
    "Module",
    "ModuleList",
    "MultiheadAttention",
    "Optional",
    "Tensor",
    "Union",
    "xavier_uniform_"
  ],
  "torch.nn.modules.upsampling": [
    "Module",
    "Optional",
    "Tensor"
  ],
  "torch.nn.modules.utils": [
    "Any",
    "Dict",
    "List",
    "repeat"
  ],
  "torch.nn.parallel.comm": [
    "List"
  ],
  "torch.nn.parallel.data_parallel": [
    "Module",
    "chain",
    "gather",
    "parallel_apply",
    "replicate",
    "scatter_kwargs"
  ],
  "torch.nn.parallel.distributed": [
    "Any",
    "Callable",
    "Enum",
    "Function",
    "Join",
    "JoinHook",
    "Joinable",
    "Module",
    "RRef",
    "ReduceOp",
    "Type",
    "Variable",
    "auto",
    "contextmanager",
    "dataclass",
    "gather",
    "is_namedtuple",
    "scatter_kwargs",
    "tree_flatten",
    "tree_unflatten"
  ],
  "torch.nn.parallel.parallel_apply": [
    "ExceptionWrapper",
    "autocast"
  ],
  "torch.nn.parallel.replicate": [
    "OrderedDict"
  ],
  "torch.nn.parallel.scatter_gather": [
    "Gather",
    "Scatter"
  ],
  "torch.nn.parameter": [
    "OrderedDict"
  ],
  "torch.nn.qat.dynamic.modules.linear": [
    "activation_is_memoryless"
  ],
  "torch.nn.qat.modules.conv": [
    "Tuple",
    "TypeVar",
    "Union"
  ],
  "torch.nn.qat.modules.embedding_ops": [
    "Tensor"
  ],
  "torch.nn.qat.modules.linear": [
    "LinearReLU",
    "is_parametrized",
    "transfer_parametrizations_and_params",
    "type_before_parametrizations"
  ],
  "torch.nn.quantizable.modules.activation": [
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.nn.quantizable.modules.rnn": [
    "Optional",
    "Tensor",
    "Tuple"
  ],
  "torch.nn.quantized": [
    "MaxPool2d"
  ],
  "torch.nn.quantized.dynamic.modules.conv": [
    "Tensor"
  ],
  "torch.nn.quantized.dynamic.modules.rnn": [
    "Dict",
    "List",
    "Optional",
    "PackedSequence",
    "Tensor",
    "Tuple",
    "Union"
  ],
  "torch.nn.quantized.functional": [
    "List",
    "Optional",
    "Tensor"
  ],
  "torch.nn.quantized.modules": [
    "MaxPool2d"
  ],
  "torch.nn.quantized.modules.batchnorm": [
    "Tensor"
  ],
  "torch.nn.quantized.modules.conv": [
    "List",
    "Optional",
    "TypeVar",
    "WeightedQuantizedModule",
    "fuse_conv_bn_weights"
  ],
  "torch.nn.quantized.modules.embedding_ops": [
    "List",
    "Optional",
    "Tensor",
    "hide_packed_params_repr"
  ],
  "torch.nn.quantized.modules.functional_modules": [
    "List",
    "Tensor"
  ],
  "torch.nn.quantized.modules.linear": [
    "Iterable",
    "Optional",
    "WeightedQuantizedModule",
    "fuse_linear_bn_weights",
    "hide_packed_params_repr",
    "type_before_parametrizations"
  ],
  "torch.nn.quantized.modules.utils": [
    "repeat"
  ],
  "torch.nn.utils.clip_grad": [
    "Iterable",
    "Union"
  ],
  "torch.nn.utils.convert_parameters": [
    "Iterable",
    "Optional"
  ],
  "torch.nn.utils.parametrizations": [
    "Enum",
    "Module",
    "Optional",
    "Tensor",
    "auto"
  ],
  "torch.nn.utils.parametrize": [
    "Dict",
    "Module",
    "ModuleDict",
    "ModuleList",
    "Optional",
    "Parameter",
    "Sequence",
    "Tensor",
    "Tuple",
    "Union",
    "contextmanager"
  ],
  "torch.nn.utils.rnn": [
    "Iterable",
    "List",
    "Optional",
    "Tensor",
    "Tuple",
    "Union",
    "namedtuple"
  ],
  "torch.nn.utils.spectral_norm": [
    "Any",
    "Module",
    "Optional",
    "TypeVar",
    "normalize"
  ],
  "torch.nn.utils.weight_norm": [
    "Any",
    "Module",
    "Parameter",
    "TypeVar",
    "UninitializedParameter",
    "norm_except_dim"
  ],
  "torch.onnx": [
    "Dict",
    "OperatorExportTypes",
    "Optional",
    "TensorProtoDataType",
    "TrainingMode"
  ],
  "torch.optim.adadelta": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.adagrad": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.adam": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.adamax": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.adamw": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.asgd": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.lbfgs": [
    "Optimizer",
    "reduce"
  ],
  "torch.optim.lr_scheduler": [
    "Counter",
    "Optimizer",
    "bisect_right",
    "wraps"
  ],
  "torch.optim.nadam": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.optimizer": [
    "chain",
    "deepcopy",
    "defaultdict"
  ],
  "torch.optim.radam": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.rmsprop": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.rprop": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.sgd": [
    "List",
    "Optimizer",
    "Optional",
    "Tensor"
  ],
  "torch.optim.sparse_adam": [
    "Optimizer"
  ],
  "torch.optim.swa_utils": [
    "Module",
    "deepcopy"
  ],
  "torch.overrides": [
    "Any",
    "Callable",
    "Dict",
    "Iterable",
    "Iterator",
    "List",
    "Set",
    "Type",
    "has_torch_function",
    "has_torch_function_unary",
    "has_torch_function_variadic"
  ],
  "torch.package.analyze.find_first_use_of_broken_modules": [
    "Dict",
    "List",
    "PackagingError"
  ],
  "torch.package.analyze.is_from_package": [
    "Any",
    "ModuleType",
    "is_mangled"
  ],
  "torch.package.analyze.trace_dependencies": [
    "Any",
    "Callable",
    "Iterable",
    "List",
    "Tuple"
  ],
  "torch.package.file_structure_representation": [
    "Dict",
    "GlobGroup",
    "GlobPattern",
    "List"
  ],
  "torch.package.find_file_dependencies": [
    "List",
    "Optional",
    "Tuple"
  ],
  "torch.package.glob_group": [
    "GlobPattern",
    "Iterable",
    "Union"
  ],
  "torch.package.importer": [
    "ABC",
    "Any",
    "Dict",
    "List",
    "ModuleType",
    "Optional",
    "Tuple",
    "abstractmethod",
    "demangle",
    "get_mangle_prefix",
    "is_mangled"
  ],
  "torch.package.package_exporter": [
    "ActionHook",
    "Any",
    "BinaryIO",
    "Callable",
    "DefaultDict",
    "DiGraph",
    "Dict",
    "Enum",
    "GlobGroup",
    "GlobPattern",
    "Importer",
    "List",
    "Optional",
    "OrderedDict",
    "OrderedImporter",
    "Path",
    "RemovableHandle",
    "Sequence",
    "Set",
    "Storage",
    "Union",
    "cast",
    "create_pickler",
    "dataclass",
    "defaultdict",
    "demangle",
    "find_files_source_depends_on",
    "is_mangled",
    "is_stdlib_module",
    "location_tag",
    "normalize_storage_type"
  ],
  "torch.package.package_importer": [
    "Any",
    "BinaryIO",
    "Callable",
    "Dict",
    "Directory",
    "DirectoryReader",
    "GlobPattern",
    "Importer",
    "List",
    "Optional",
    "PackageMangler",
    "PackageUnpickler",
    "Path",
    "Union",
    "WeakValueDictionary",
    "cast",
    "contextmanager",
    "demangle"
  ],
  "torch.profiler": [
    "DeviceType",
    "ProfilerActivity",
    "kineto_available",
    "record_function"
  ],
  "torch.profiler.profiler": [
    "Any",
    "Callable",
    "Dict",
    "Enum",
    "Iterable",
    "List",
    "Optional",
    "ProfilerActivity",
    "Tuple",
    "kineto_available",
    "partial",
    "warn"
  ],
  "torch.quantization": [
    "ABC",
    "DeQuantStub",
    "FakeQuantize",
    "FakeQuantizeBase",
    "FixedQParamsFakeQuantize",
    "FusedMovingAvgObsFakeQuantize",
    "HistogramObserver",
    "MinMaxObserver",
    "MovingAverageMinMaxObserver",
    "MovingAveragePerChannelMinMaxObserver",
    "NoopObserver",
    "ObserverBase",
    "PerChannelMinMaxObserver",
    "PlaceholderObserver",
    "QConfig",
    "QConfigAny",
    "QConfigDynamic",
    "QuantStub",
    "QuantType",
    "QuantWrapper",
    "RecordingObserver",
    "add_module_to_qconfig_obs_ctr",
    "add_observer_",
    "add_quant_dequant",
    "assert_valid_qconfig",
    "convert",
    "convert_dynamic_jit",
    "convert_jit",
    "default_affine_fixed_qparams_fake_quant",
    "default_debug_observer",
    "default_dynamic_quant_observer",
    "default_fake_quant",
    "default_float_qparams_observer",
    "default_fused_act_fake_quant",
    "default_fused_per_channel_wt_fake_quant",
    "default_fused_wt_fake_quant",
    "default_histogram_fake_quant",
    "default_histogram_observer",
    "default_observer",
    "default_per_channel_weight_fake_quant",
    "default_per_channel_weight_observer",
    "default_placeholder_observer",
    "default_symmetric_fixed_qparams_fake_quant",
    "default_weight_fake_quant",
    "default_weight_observer",
    "disable_fake_quant",
    "disable_observer",
    "enable_fake_quant",
    "enable_observer",
    "fuse_conv_bn",
    "fuse_conv_bn_jit",
    "fuse_conv_bn_relu",
    "fuse_linear_bn",
    "fuse_modules",
    "get_default_compare_output_module_list",
    "get_default_dynamic_quant_module_mappings",
    "get_default_float_to_quantized_operator_mappings",
    "get_default_qat_module_mappings",
    "get_default_qat_qconfig",
    "get_default_qconfig",
    "get_default_qconfig_propagation_list",
    "get_default_static_quant_module_mappings",
    "get_dynamic_quant_module_class",
    "get_fuser_method",
    "get_observer_dict",
    "get_observer_state_dict",
    "get_quantized_operator",
    "get_static_quant_module_class",
    "get_unique_devices_",
    "is_activation_post_process",
    "load_observer_state_dict",
    "no_observer_set",
    "prepare",
    "prepare_dynamic_jit",
    "prepare_jit",
    "prepare_qat",
    "propagate_qconfig_",
    "qconfig_equals",
    "quant_type_to_str",
    "quantize",
    "quantize_dynamic",
    "quantize_dynamic_jit",
    "quantize_jit",
    "quantize_qat",
    "register_activation_post_process_hook",
    "script_qconfig",
    "script_qconfig_dict",
    "swap_module"
  ],
  "torch.quantization.fake_quantize": [
    "FakeQuantize",
    "FakeQuantizeBase",
    "FixedQParamsFakeQuantize",
    "FusedMovingAvgObsFakeQuantize",
    "default_affine_fixed_qparams_fake_quant",
    "default_fake_quant",
    "default_fused_act_fake_quant",
    "default_fused_per_channel_wt_fake_quant",
    "default_fused_wt_fake_quant",
    "default_histogram_fake_quant",
    "default_per_channel_weight_fake_quant",
    "default_symmetric_fixed_qparams_fake_quant",
    "default_weight_fake_quant",
    "disable_fake_quant",
    "disable_observer",
    "enable_fake_quant",
    "enable_observer"
  ],
  "torch.quantization.fuse_modules": [
    "fuse_conv_bn",
    "fuse_conv_bn_relu",
    "fuse_known_modules",
    "fuse_modules",
    "get_fuser_method"
  ],
  "torch.quantization.fuser_method_mappings": [
    "fuse_conv_bn",
    "fuse_conv_bn_relu",
    "fuse_linear_bn",
    "get_fuser_method"
  ],
  "torch.quantization.observer": [
    "ABC",
    "HistogramObserver",
    "MinMaxObserver",
    "MovingAverageMinMaxObserver",
    "MovingAveragePerChannelMinMaxObserver",
    "NoopObserver",
    "ObserverBase",
    "PerChannelMinMaxObserver",
    "PlaceholderObserver",
    "RecordingObserver",
    "default_debug_observer",
    "default_dynamic_quant_observer",
    "default_float_qparams_observer",
    "default_histogram_observer",
    "default_observer",
    "default_per_channel_weight_observer",
    "default_placeholder_observer",
    "default_weight_observer",
    "get_observer_state_dict",
    "load_observer_state_dict"
  ],
  "torch.quantization.qconfig": [
    "QConfig",
    "QConfigAny",
    "QConfigDynamic",
    "add_module_to_qconfig_obs_ctr",
    "assert_valid_qconfig",
    "get_default_qat_qconfig",
    "get_default_qconfig",
    "qconfig_equals"
  ],
  "torch.quantization.quant_type": [
    "QuantType",
    "quant_type_to_str"
  ],
  "torch.quantization.quantization_mappings": [
    "get_default_compare_output_module_list",
    "get_default_dynamic_quant_module_mappings",
    "get_default_float_to_quantized_operator_mappings",
    "get_default_qat_module_mappings",
    "get_default_qconfig_propagation_list",
    "get_default_static_quant_module_mappings",
    "get_dynamic_quant_module_class",
    "get_quantized_operator",
    "get_static_quant_module_class",
    "no_observer_set"
  ],
  "torch.quantization.quantize": [
    "add_observer_",
    "add_quant_dequant",
    "convert",
    "get_observer_dict",
    "get_unique_devices_",
    "is_activation_post_process",
    "prepare",
    "prepare_qat",
    "propagate_qconfig_",
    "quantize",
    "quantize_dynamic",
    "quantize_qat",
    "register_activation_post_process_hook",
    "swap_module"
  ],
  "torch.quantization.quantize_jit": [
    "convert_dynamic_jit",
    "convert_jit",
    "fuse_conv_bn_jit",
    "prepare_dynamic_jit",
    "prepare_jit",
    "quantize_dynamic_jit",
    "quantize_jit",
    "script_qconfig",
    "script_qconfig_dict"
  ],
  "torch.quantization.stubs": [
    "DeQuantStub",
    "QuantStub",
    "QuantWrapper"
  ],
  "torch.quasirandom": [
    "Optional"
  ],
  "torch.random": [
    "Generator"
  ],
  "torch.serialization": [
    "Any",
    "BinaryIO",
    "Dict",
    "IO",
    "Optional",
    "Storage",
    "Tuple",
    "Type",
    "Union",
    "cast",
    "closing",
    "contextmanager",
    "get_source_lines_and_file"
  ],
  "torch.sparse": [
    "DType",
    "DimOrDims",
    "List",
    "Optional",
    "Tensor",
    "Tuple",
    "Union",
    "addmm",
    "log_softmax",
    "mm",
    "sampled_addmm",
    "softmax"
  ],
  "torch.special": [
    "Tensor",
    "digamma",
    "entr",
    "erf",
    "erfc",
    "erfcx",
    "erfinv",
    "exp2",
    "expit",
    "expm1",
    "gammainc",
    "gammaincc",
    "gammaln",
    "i0",
    "i0e",
    "i1",
    "i1e",
    "log1p",
    "log_ndtr",
    "log_softmax",
    "logit",
    "logsumexp",
    "multigammaln",
    "ndtr",
    "ndtri",
    "polygamma",
    "psi",
    "round",
    "sinc",
    "softmax",
    "xlog1py",
    "xlogy",
    "zeta"
  ],
  "torch.storage": [
    "Any",
    "Storage",
    "Type",
    "TypeVar",
    "Union",
    "cast",
    "lru_cache"
  ],
  "torch.testing": [
    "FileCheck",
    "rand",
    "randn",
    "all_types",
    "all_types_and",
    "all_types_and_complex",
    "all_types_and_complex_and",
    "all_types_and_half",
    "assert_allclose",
    "assert_close",
    "complex_types",
    "double_types",
    "empty_types",
    "floating_and_complex_types",
    "floating_and_complex_types_and",
    "floating_types",
    "floating_types_and",
    "floating_types_and_half",
    "get_all_complex_dtypes",
    "get_all_device_types",
    "get_all_dtypes",
    "get_all_fp_dtypes",
    "get_all_int_dtypes",
    "get_all_math_dtypes",
    "integral_types",
    "integral_types_and",
    "make_non_contiguous",
    "make_tensor"
  ],
  "torch.torch_version": [
    "Any",
    "Iterable"
  ],
  "torch.types": [
    "Any",
    "Device",
    "List",
    "Number",
    "Sequence",
    "Tuple",
    "Union"
  ],
  "torch.utils.benchmark.utils.common": [
    "Any",
    "DefaultDict",
    "Dict",
    "Iterable",
    "Iterator",
    "List",
    "Optional",
    "Tuple",
    "cast"
  ],
  "torch.utils.benchmark.utils.compare": [
    "DefaultDict",
    "List",
    "Optional",
    "Tuple"
  ],
  "torch.utils.benchmark.utils.cpp_jit": [
    "Any",
    "CallgrindModuleType",
    "List",
    "Optional",
    "TimeitModuleType"
  ],
  "torch.utils.benchmark.utils.fuzzer": [
    "Any",
    "Callable",
    "Dict",
    "List",
    "Optional",
    "Tuple",
    "Union"
  ],
  "torch.utils.benchmark.utils.sparse_fuzzer": [
    "FuzzedTensor",
    "Number",
    "Optional",
    "Tuple",
    "Union"
  ],
  "torch.utils.benchmark.utils.timer": [
    "Any",
    "Callable",
    "Dict",
    "List",
    "NoReturn",
    "Optional",
    "TimeitModuleType",
    "TimerClass",
    "Tuple",
    "Type",
    "Union",
    "overload",
    "timer"
  ],
  "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface": [
    "Any",
    "Callable",
    "CallgrindModuleType",
    "CompletedProcessType",
    "DefaultDict",
    "Dict",
    "Generator",
    "List",
    "NamedTuple",
    "Optional",
    "Tuple",
    "Union",
    "cast"
  ],
  "torch.utils.cpp_extension": [
    "ExtensionVersioner",
    "FileBaton",
    "GeneratedFileCleaner",
    "List",
    "Optional",
    "TorchVersion",
    "Tuple",
    "Union",
    "build_ext",
    "get_hip_file_path"
  ],
  "torch.utils": [
    "disable_minidumps",
    "enable_minidumps",
    "enable_minidumps_on_exceptions"
  ],
  "torch.utils.data": [
    "argument_validation",
    "default_collate",
    "default_convert",
    "functional_datapipe",
    "get_worker_info",
    "guaranteed_datapipes_determinism",
    "non_deterministic",
    "runtime_validation",
    "runtime_validation_disabled"
  ],
  "torch.utils.data.communication.eventloop": [
    "IterDataPipe",
    "MapDataPipe"
  ],
  "torch.utils.data.communication.iter": [
    "IterDataPipe"
  ],
  "torch.utils.data.communication.map": [
    "MapDataPipe"
  ],
  "torch.utils.data.dataloader": [
    "Any",
    "BatchSampler",
    "Callable",
    "Dataset",
    "ExceptionWrapper",
    "Generic",
    "IterDataPipe",
    "Iterable",
    "IterableDataset",
    "List",
    "Optional",
    "RandomSampler",
    "Sampler",
    "Sequence",
    "SequentialSampler",
    "TypeVar",
    "Union",
    "default_collate",
    "default_convert",
    "get_worker_info"
  ],
  "torch.utils.data.dataloader_experimental": [
    "Any",
    "DataLoader",
    "IterDataPipe",
    "IterableWrapper",
    "List"
  ],
  "torch.utils.data.datapipes.dataframe": [
    "DFIterDataPipe"
  ],
  "torch.utils.data.datapipes.dataframe.dataframes": [
    "Any",
    "DFIterDataPipe",
    "DataChunkDF",
    "Dict",
    "IterDataPipe",
    "List",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.dataframe.datapipes": [
    "DFIterDataPipe",
    "IterDataPipe",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.dataframe.structures": [
    "DataChunk"
  ],
  "torch.utils.data.datapipes.datapipe": [
    "Callable",
    "Dataset",
    "Dict",
    "Generic",
    "IterableDataset",
    "Iterator",
    "Optional",
    "SerializationType",
    "TypeVar",
    "deserialize_fn",
    "serialize_fn"
  ],
  "torch.utils.data.datapipes.iter.callable": [
    "Callable",
    "IterDataPipe",
    "Iterator",
    "Sized",
    "TypeVar",
    "check_lambda_fn",
    "default_collate",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.iter.combinatorics": [
    "Dict",
    "IterDataPipe",
    "Iterator",
    "List",
    "Optional",
    "Sampler",
    "SequentialSampler",
    "Sized",
    "Tuple",
    "Type",
    "TypeVar",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.iter.combining": [
    "Any",
    "Callable",
    "Deque",
    "IterDataPipe",
    "Iterator",
    "List",
    "Optional",
    "SerializationType",
    "Set",
    "Sized",
    "Tuple",
    "TypeVar",
    "check_lambda_fn",
    "deque",
    "deserialize_fn",
    "functional_datapipe",
    "serialize_fn"
  ],
  "torch.utils.data.datapipes.iter.filelister": [
    "IterDataPipe",
    "IterableWrapper",
    "Iterator",
    "List",
    "Sequence",
    "Union",
    "get_file_pathnames_from_root"
  ],
  "torch.utils.data.datapipes.iter.fileopener": [
    "IOBase",
    "IterDataPipe",
    "Iterable",
    "Optional",
    "Tuple",
    "deprecation_warning",
    "get_file_binaries_from_pathnames"
  ],
  "torch.utils.data.datapipes.iter.grouping": [
    "Any",
    "Callable",
    "DataChunk",
    "DefaultDict",
    "IterDataPipe",
    "Iterator",
    "List",
    "Optional",
    "Sized",
    "TypeVar",
    "check_lambda_fn",
    "defaultdict",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.iter.routeddecoder": [
    "Any",
    "BufferedIOBase",
    "Callable",
    "Decoder",
    "IterDataPipe",
    "Iterable",
    "Iterator",
    "Sized",
    "Tuple",
    "decoder_basichandlers",
    "decoder_imagehandler",
    "deprecation_warning",
    "extension_extract_fn",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.iter.selecting": [
    "Callable",
    "IterDataPipe",
    "Iterator",
    "TypeVar",
    "check_lambda_fn",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.iter.streamreader": [
    "IterDataPipe",
    "Tuple"
  ],
  "torch.utils.data.datapipes.iter.utils": [
    "IterDataPipe"
  ],
  "torch.utils.data.datapipes.map.callable": [
    "Callable",
    "MapDataPipe",
    "TypeVar",
    "check_lambda_fn",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.map.combinatorics": [
    "Iterator",
    "List",
    "MapDataPipe",
    "Optional",
    "TypeVar",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.map.combining": [
    "MapDataPipe",
    "Sized",
    "Tuple",
    "TypeVar",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.map.grouping": [
    "DataChunk",
    "List",
    "MapDataPipe",
    "Optional",
    "Sized",
    "TypeVar",
    "functional_datapipe"
  ],
  "torch.utils.data.datapipes.map.utils": [
    "MapDataPipe"
  ],
  "torch.utils.data.datapipes.utils.common": [
    "IOBase",
    "Iterable",
    "List",
    "Optional",
    "Tuple",
    "Union"
  ],
  "torch.utils.data.datapipes.utils.decoder": [
    "StreamWrapper"
  ],
  "torch.utils.data.dataset": [
    "Generator",
    "Generic",
    "Iterable",
    "Iterator",
    "List",
    "Optional",
    "Sequence",
    "Tensor",
    "Tuple",
    "TypeVar",
    "randperm"
  ],
  "torch.utils.data.distributed": [
    "Dataset",
    "Iterator",
    "Optional",
    "Sampler",
    "TypeVar"
  ],
  "torch.utils.data.graph": [
    "Any",
    "Dict",
    "IterDataPipe",
    "MapDataPipe",
    "Set"
  ],
  "torch.utils.data.graph_settings": [
    "Shuffler"
  ],
  "torch.utils.data.sampler": [
    "Generic",
    "Iterable",
    "Iterator",
    "List",
    "Optional",
    "Sequence",
    "Sized",
    "Tensor",
    "TypeVar",
    "Union"
  ],
  "torch.utils.dlpack": [
    "Any",
    "to_dlpack"
  ],
  "torch.utils.hipify.hipify_python": [
    "Dict",
    "HipifyFinalResult",
    "HipifyResult",
    "Iterable",
    "Iterator",
    "List",
    "Mapping",
    "Optional"
  ],
  "torch.utils.hooks": [
    "Any",
    "OrderedDict"
  ],
  "torch.utils.show_pickle": [
    "Any",
    "BinaryIO",
    "IO",
    "Union"
  ],
  "torch.utils.tensorboard.summary": [
    "HistogramProto",
    "Optional",
    "PrCurvePluginData",
    "Summary",
    "SummaryMetadata",
    "TensorProto",
    "TensorShapeProto",
    "TextPluginData",
    "convert_to_HWC",
    "make_np",
    "range"
  ],
  "torch.utils.tensorboard.writer": [
    "Event",
    "EventFileWriter",
    "ProjectorConfig",
    "SessionLog",
    "audio",
    "custom_scalars",
    "figure_to_image",
    "get_embedding_info",
    "graph",
    "histogram",
    "histogram_raw",
    "hparams",
    "image",
    "image_boxes",
    "load_onnx_graph",
    "make_mat",
    "make_np",
    "make_sprite",
    "make_tsv",
    "mesh",
    "pr_curve",
    "pr_curve_raw",
    "scalar",
    "text",
    "video",
    "write_pbtxt"
  ],
  "torch": [
    "Union",
    "Set",
    "Callable",
    "CudaByteStorageBase",
    "DisableTorchFunction",
    "Generator",
    "LoggerBase",
    "classproperty",
    "get_file_path",
    "lobpcg",
    "pca_lowrank",
    "prepare_multiprocessing_environment",
    "quantized_gru",
    "quantized_lstm",
    "set_printoptions",
    "svd_lowrank",
    "to_dlpack",
    "vmap"
  ]
}
